{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d0bad-2053-4fb7-9211-ebade9a3433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "from tklearn.nn.prototypes import PrototypeForSequenceClassification\n",
    "from tklearn.nn.prototypes.loss import get_prototype_map\n",
    "from tklearn.nn.prototypes.helpers import compute_prototypes\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME_OR_PATH = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "model = PrototypeForSequenceClassification.from_pretrained(MODEL_NAME_OR_PATH)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "# book review sentiment examples (0: negative, 1: positive, 2: neutral)\n",
    "# each example must have at least 10 tokens and 10 examples\n",
    "examples = [\n",
    "    # positive examples\n",
    "    \"I love this book, it's so interesting.\",\n",
    "    \"The book is great, but the ending is so sad.\",\n",
    "    \"I'm so glad I bought this book.\",\n",
    "    # negative examples\n",
    "    \"This book is so boring, I can't even finish it.\",\n",
    "    \"I can't believe how bad this book is.\",\n",
    "    \"I wish I never bought this book.\",\n",
    "    # neutral examples\n",
    "    \"The book is okay, but I don't like it.\",\n",
    "    \"I don't know how I feel about this book.\",\n",
    "    \"I don't have an opinion about this book.\",\n",
    "]\n",
    "\n",
    "\n",
    "batch = tokenize(examples)\n",
    "batch[\"labels\"] = torch.tensor([1, 1, 1, 0, 0, 0, 2, 2, 2], dtype=torch.long)\n",
    "\n",
    "outputs = model.predict_step(batch)\n",
    "\n",
    "loss = model.compute_loss(batch, outputs)\n",
    "\n",
    "print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "batch_output = model.predict_step(batch, batch_idx=0, dataloader_idx=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.prototypes = compute_prototypes(model, [batch])\n",
    "    print(model.compute_metric_inputs(batch, batch_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b4896-e4d4-44cf-a1aa-f11b5a158eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooler_output = batch_output[\"pooler_output\"]\n",
    "\n",
    "targets = batch[\"labels\"]\n",
    "\n",
    "pooler_output = pooler_output.cpu().detach().numpy()\n",
    "pooler_output = np.concatenate([pooler_output, model.prototypes])\n",
    "\n",
    "tsne = TSNE(\n",
    "    random_state=1,\n",
    "    n_iter=15000,\n",
    "    metric=\"cosine\",\n",
    "    perplexity=5,\n",
    ")\n",
    "\n",
    "embs = tsne.fit_transform(pooler_output)\n",
    "# Add to dataframe for convenience\n",
    "label_names = [f\"Label {i}\" for i in range(len(model.prototypes))]\n",
    "df = pd.DataFrame(examples + label_names, columns=[\"text\"])\n",
    "\n",
    "df[\"x\"] = embs[:, 0]\n",
    "df[\"y\"] = embs[:, 1]\n",
    "df[\"c\"] = targets.tolist() + list(range(len(model.prototypes)))\n",
    "\n",
    "# Plot the embeddings\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df[\"x\"], df[\"y\"], c=df[\"c\"], cmap=\"viridis\")\n",
    "for i, txt in enumerate(df[\"text\"]):\n",
    "    ax.annotate(txt, (df[\"x\"][i], df[\"y\"][i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8a8caa-66e2-4441-9826-ef5e2ec16778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
