{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4be6d-d22d-41a3-9197-d9903ed8be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89f5fa-9fb2-4cd6-a74c-a350297f93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tklearn.metrics import Accuracy, ArrayAccumulator\n",
    "from tklearn.nn import Trainer, Evaluator\n",
    "from tklearn.nn.callbacks import ProgbarLogger, EarlyStopping\n",
    "from tklearn.nn.transformers import TransformerForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c9740a-eca6-4a17-b937-4c24d9975982",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME_OR_PATH = \"google-bert/bert-base-uncased\"\n",
    "DATASET = \"yelp_review_full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a92543-1d7b-4061-aa4f-e3393d3926dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(DATASET)\n",
    "\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f1717-9942-42e0-8239-ffc74cf2832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5edf743-902b-49ac-90e8-7569b14fa619",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e70a6-8d16-4c57-97ab-f53abfa8ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(100))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8478beb-f629-4868-82bf-48241d09c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerForSequenceClassification(MODEL_NAME_OR_PATH, num_labels=5)\n",
    "\n",
    "model.to(\"mps\")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=16)\n",
    "valid_dataloader = DataLoader(small_eval_dataset, batch_size=32)\n",
    "\n",
    "evaluator = Evaluator(model, valid_dataloader, callbacks=[ProgbarLogger()], metrics={\"acuracy\": Accuracy()}, prefix=\"valid_\")\n",
    "\n",
    "trainer = Trainer(model, train_dataloader, optimizer=optimizer, callbacks=[ProgbarLogger(), EarlyStopping(patience=0)], evaluator=evaluator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba72734-3695-4232-bcdd-88843cc14c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922eed6-e0a6-4245-81ec-e4ff11612249",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_accum = Evaluator(model, valid_dataloader, callbacks=[ProgbarLogger()], metrics={\n",
    "    \"embedding\": ArrayAccumulator(\"embedding\")\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd399b9-065b-4e99-8840-c9ef34079426",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = embedding_accum.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca5847-884e-4e21-a901-d79fc2337838",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"embedding\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd75a25-a8e5-4462-a17b-c582f7d64fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = [0, 1, 2, 2, 2]\n",
    "y_pred = [0, 0, 2, 2, 1]\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c768b6de-94db-4c8f-8ad5-3117506c2cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890da881-f7dc-4195-9765-f1482c521c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1, 1, 0]\n",
    "y_true = [1, 1, 1]\n",
    "print(classification_report(y_true, y_pred, labels=[1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a0e1ca-1baa-416a-b794-d91434f21b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347a3df-c6d7-4e1e-a0f7-29280ab9ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import warnings\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backend_bases import RendererBase\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "try:\n",
    "    from umap import UMAP\n",
    "except ImportError:\n",
    "    UMAP = None\n",
    "\n",
    "sns.set_theme(context=\"paper\", style=\"whitegrid\")\n",
    "\n",
    "available_styles = {style: style for style in plt.style.available}\n",
    "\n",
    "available_styles[\"seaborn\"] = next(\n",
    "    filter(\n",
    "        lambda x: x.startswith(\"seaborn\") and x.endswith(\"whitegrid\"),\n",
    "        plt.style.available,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def get_style(style: str) -> str | None:\n",
    "    return available_styles.get(style)\n",
    "\n",
    "\n",
    "def embed2d(X: np.ndarray, embedder=\"umap\") -> np.ndarray:  # noqa\n",
    "    embedder = embedder.lower()\n",
    "    if embedder == \"umap\" and UMAP is not None:\n",
    "        X_embedded = UMAP(n_components=2).fit_transform(X)\n",
    "    elif embedder in {\"tsne\", \"t-sne\", \"umap\"}:\n",
    "        if embedder == \"umap\":\n",
    "            msg = \"umap is not installed, falling back to t-SNE\"\n",
    "            warnings.warn(msg, stacklevel=1)\n",
    "        X_embedded = TSNE(n_components=2).fit_transform(X)\n",
    "    else:\n",
    "        msg = f\"embedder {embedder} not supported\"\n",
    "        raise ValueError(msg)\n",
    "    return X_embedded\n",
    "\n",
    "\n",
    "\n",
    "def set_legend(\n",
    "    fig: plt.Figure,\n",
    "    ax: plt.Axes,\n",
    "    title: str,\n",
    "    frameon: bool = True,\n",
    "    fancybox: bool = True,\n",
    "    loc: str = \"upper right\",\n",
    "    bbox_to_anchor: Tuple[float, float] | None = None,\n",
    "    ncols: int = 1,\n",
    "    max_ncols: int | None = None,\n",
    "):\n",
    "    legend = ax.legend(\n",
    "        title=title,\n",
    "        frameon=frameon,\n",
    "        fancybox=fancybox,\n",
    "        loc=loc,\n",
    "        bbox_to_anchor=bbox_to_anchor,\n",
    "        ncols=ncols,\n",
    "    )\n",
    "    if max_ncols is None:\n",
    "        return legend\n",
    "    renderer = get_renderer(fig)\n",
    "    legend_height = legend.get_window_extent(renderer).height\n",
    "    plot_height = fig.get_window_extent(renderer).height\n",
    "    # If the legend is taller, increase the number of columns\n",
    "    if legend_height <= plot_height:\n",
    "        return legend\n",
    "    ncols = 2\n",
    "    while ncols <= max_ncols:\n",
    "        legend.remove()\n",
    "        legend = ax.legend(\n",
    "            title=title,\n",
    "            frameon=frameon,\n",
    "            fancybox=fancybox,\n",
    "            loc=loc,\n",
    "            bbox_to_anchor=bbox_to_anchor,\n",
    "            ncol=ncols,\n",
    "        )\n",
    "        renderer = get_renderer(fig)\n",
    "        legend_height = legend.get_window_extent(renderer).height\n",
    "        if legend_height <= plot_height:\n",
    "            break\n",
    "        ncols += 1\n",
    "    return legend\n",
    "\n",
    "\n",
    "\n",
    "def get_renderer(fig) -> RendererBase:\n",
    "    if hasattr(fig.canvas, \"get_renderer\"):\n",
    "        return fig.canvas.get_renderer()\n",
    "    elif hasattr(fig, \"_get_renderer\"):\n",
    "        return fig._get_renderer()\n",
    "    backend = mpl.get_backend()\n",
    "    msg = f\"could not find a renderer for the '{backend}' backend.\"\n",
    "    raise AttributeError(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269a657-fd03-4d90-929a-a27547cbb986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib.textpath import TextPath\n",
    "from matplotlib.transforms import Bbox\n",
    "from matplotlib.legend import Legend\n",
    "\n",
    "# from fluxai.plotting.utils import embed2d, get_style\n",
    "\n",
    "__all__ = [\n",
    "    \"plot_embedding\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def plot_embedding(\n",
    "    data: pd.DataFrame,\n",
    "    x: str = \"embedding\",\n",
    "    y: str = \"label\",\n",
    "    style: Any = \"seaborn\",\n",
    "    cmap: Any = \"rainbow\",\n",
    "    alpha: float = 0.5,\n",
    "    figsize: Tuple[int, int] = (10, 8),\n",
    "    embedder: str = \"umap\",\n",
    "    dpi: float = 100,\n",
    "    legend_loc: str = \"upper right\",\n",
    "    legend_max_ncols: int = 5,\n",
    "):\n",
    "    x_col, y_col = x, y\n",
    "    X = np.array(data[x_col].tolist())\n",
    "    X_embedded = embed2d(X, embedder=embedder)\n",
    "    labels = pd.Series(data[y_col]).astype(\"category\")\n",
    "    style = get_style(style)\n",
    "    cmap = plt.colormaps.get_cmap(cmap)\n",
    "    num_classes = len(labels.cat.categories)\n",
    "    with plt.style.context(style=style):\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        fig.set_dpi(dpi)\n",
    "        for label in labels.cat.categories:\n",
    "            label_id = labels.cat.categories.get_loc(label)\n",
    "            idx = np.where(labels == label)\n",
    "            x, y = X_embedded[idx].T\n",
    "            c = cmap(label_id / num_classes)\n",
    "            ax.scatter(\n",
    "                x=x, y=y, color=c, label=label, alpha=alpha, edgecolors=\"none\"\n",
    "            )\n",
    "        set_legend(\n",
    "            fig,\n",
    "            ax,\n",
    "            title=y_col,\n",
    "            loc=legend_loc,\n",
    "            max_ncols=legend_max_ncols,\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        ax.grid(True)\n",
    "    return figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde8f3c-a2b7-4569-9232-1a5be6dcea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"embedding\": res[\"embedding\"].tolist()[:100], \"label\": [f\"Label {i}\" for i in range(100)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6815f861-fc15-43d2-9da1-e87ee0fcde1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_embedding(df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a95015-502b-40c9-b997-77f1483ead24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
