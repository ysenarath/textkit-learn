{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4be6d-d22d-41a3-9197-d9903ed8be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89f5fa-9fb2-4cd6-a74c-a350297f93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tklearn.metrics import Accuracy, ArrayAccumulator\n",
    "from tklearn.nn import Trainer, Evaluator\n",
    "from tklearn.nn.callbacks import ProgbarLogger, EarlyStopping\n",
    "from tklearn.nn.transformers import TransformerForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c9740a-eca6-4a17-b937-4c24d9975982",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME_OR_PATH = \"google-bert/bert-base-uncased\"\n",
    "DATASET = \"yelp_review_full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a92543-1d7b-4061-aa4f-e3393d3926dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(DATASET)\n",
    "\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f1717-9942-42e0-8239-ffc74cf2832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5edf743-902b-49ac-90e8-7569b14fa619",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e70a6-8d16-4c57-97ab-f53abfa8ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(100))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8478beb-f629-4868-82bf-48241d09c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerForSequenceClassification.from_pretrained(MODEL_NAME_OR_PATH, num_labels=5)\n",
    "\n",
    "model.to(\"mps\")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=16)\n",
    "valid_dataloader = DataLoader(small_eval_dataset, batch_size=32)\n",
    "\n",
    "evaluator = Evaluator(model, valid_dataloader, callbacks=[ProgbarLogger()], metrics={\"acuracy\": Accuracy()}, prefix=\"valid_\")\n",
    "\n",
    "trainer = Trainer(model, train_dataloader, optimizer=optimizer, callbacks=[ProgbarLogger(), EarlyStopping(patience=0)], evaluator=evaluator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba72734-3695-4232-bcdd-88843cc14c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c498727c-9168-4ae5-be09-c481e0e5bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922eed6-e0a6-4245-81ec-e4ff11612249",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_accum = Evaluator(model, valid_dataloader, callbacks=[ProgbarLogger()], metrics={\n",
    "    \"embedding\": ArrayAccumulator(\"embedding\")\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a052e-4f09-4af2-a1e1-e7b3cc1901ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd399b9-065b-4e99-8840-c9ef34079426",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = embedding_accum.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347a3df-c6d7-4e1e-a0f7-29280ab9ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import warnings\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backend_bases import RendererBase\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "try:\n",
    "    from umap import UMAP\n",
    "except ImportError:\n",
    "    UMAP = None\n",
    "\n",
    "sns.set_theme(context=\"paper\", style=\"whitegrid\")\n",
    "\n",
    "available_styles = {style: style for style in plt.style.available}\n",
    "\n",
    "available_styles[\"seaborn\"] = next(\n",
    "    filter(\n",
    "        lambda x: x.startswith(\"seaborn\") and x.endswith(\"whitegrid\"),\n",
    "        plt.style.available,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def get_style(style: str) -> str | None:\n",
    "    return available_styles.get(style)\n",
    "\n",
    "\n",
    "def embed2d(X: np.ndarray, embedder=\"umap\") -> np.ndarray:  # noqa\n",
    "    embedder = embedder.lower()\n",
    "    if embedder == \"umap\" and UMAP is not None:\n",
    "        X_embedded = UMAP(n_components=2).fit_transform(X)\n",
    "    elif embedder in {\"tsne\", \"t-sne\", \"umap\"}:\n",
    "        if embedder == \"umap\":\n",
    "            msg = \"umap is not installed, falling back to t-SNE\"\n",
    "            warnings.warn(msg, stacklevel=1)\n",
    "        X_embedded = TSNE(n_components=2).fit_transform(X)\n",
    "    else:\n",
    "        msg = f\"embedder {embedder} not supported\"\n",
    "        raise ValueError(msg)\n",
    "    return X_embedded\n",
    "\n",
    "\n",
    "def get_renderer(fig: plt.Figure) -> RendererBase:\n",
    "    if hasattr(fig.canvas, \"get_renderer\"):\n",
    "        return fig.canvas.get_renderer()\n",
    "    elif hasattr(fig, \"_get_renderer\"):\n",
    "        return fig._get_renderer()\n",
    "    backend = mpl.get_backend()\n",
    "    msg = f\"could not find a renderer for the '{backend}' backend.\"\n",
    "    raise AttributeError(msg)\n",
    "\n",
    "\n",
    "def set_legend(\n",
    "    handles,\n",
    "    fig: plt.Figure,\n",
    "    ax: plt.Axes,\n",
    "    title: str,\n",
    "    frameon: bool = True,\n",
    "    fancybox: bool = True,\n",
    "    loc: str = \"upper left\",\n",
    "    bbox_to_anchor: Tuple[float, float] | None = None,\n",
    "    ncols: int = 1,\n",
    "    max_ncols: int | None = None,\n",
    "):\n",
    "    renderer = get_renderer(fig)\n",
    "    plot_extent = ax.get_tightbbox(renderer)\n",
    "    plot_height, plot_width = (\n",
    "        plot_extent.height / fig.dpi,\n",
    "        plot_extent.width / fig.dpi,\n",
    "    )\n",
    "    labels = [s.get_label() for s in handles]\n",
    "    legend = ax.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        title=title,\n",
    "        frameon=frameon,\n",
    "        fancybox=fancybox,\n",
    "        loc=loc,\n",
    "        bbox_to_anchor=bbox_to_anchor,\n",
    "        ncols=ncols,\n",
    "    )\n",
    "    # legend width to plot width and adjust size of ax and width of plot\n",
    "    legend_extent = legend.get_tightbbox(renderer)\n",
    "    legend_height, legend_width = (\n",
    "        legend_extent.height / fig.dpi,\n",
    "        legend_extent.width / fig.dpi,\n",
    "    )\n",
    "    fig.set_size_inches(legend_width + plot_width, plot_height, forward=True)\n",
    "    if max_ncols is None:\n",
    "        return legend\n",
    "    # If the legend is taller, increase the number of columns\n",
    "    ncols = 2\n",
    "    while (ncols <= max_ncols) and (legend_height + 1 >= plot_height):\n",
    "        fig.set_size_inches(plot_width, plot_height, forward=True)\n",
    "        legend.remove()\n",
    "        legend = ax.legend(\n",
    "            handles,\n",
    "            labels,\n",
    "            title=title,\n",
    "            frameon=frameon,\n",
    "            fancybox=fancybox,\n",
    "            loc=loc,\n",
    "            bbox_to_anchor=bbox_to_anchor,\n",
    "            ncol=ncols,\n",
    "        )\n",
    "        # renderer = get_renderer(fig)\n",
    "        legend_extent = legend.get_tightbbox(renderer)\n",
    "        legend_height, legend_width = (\n",
    "            legend_extent.height / fig.dpi,\n",
    "            legend_extent.width / fig.dpi,\n",
    "        )\n",
    "        fig.set_size_inches(\n",
    "            legend_width + plot_width, plot_height, forward=True\n",
    "        )\n",
    "        ncols += 1\n",
    "    return legend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269a657-fd03-4d90-929a-a27547cbb986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# from fluxai.plotting.utils import embed2d, get_style, set_legend\n",
    "\n",
    "__all__ = [\n",
    "    \"plot_embedding\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def plot_embedding(\n",
    "    data: pd.DataFrame,\n",
    "    x: str = \"embedding\",\n",
    "    y: str = \"label\",\n",
    "    style: Any = \"seaborn\",\n",
    "    cmap: Any = \"rainbow\",\n",
    "    alpha: float = 0.5,\n",
    "    figsize: Tuple[int, int] = (10, 10),\n",
    "    embedder: str = \"umap\",\n",
    "    dpi: float = 100,\n",
    "    legend_loc: str = \"upper left\",\n",
    "    legend_max_ncols: int = 5,\n",
    "):\n",
    "    x_col, y_col = x, y\n",
    "    X = np.array(data[x_col].tolist())\n",
    "    X_embedded = embed2d(X, embedder=embedder)\n",
    "    labels = pd.Series(data[y_col]).astype(\"category\")\n",
    "    style = get_style(style)\n",
    "    cmap = plt.colormaps.get_cmap(cmap)\n",
    "    num_classes = len(labels.cat.categories)\n",
    "    with plt.style.context(style=style):\n",
    "        fig, ax = plt.subplots(figsize=figsize, tight_layout=True)\n",
    "        fig.set_dpi(dpi)\n",
    "        handles = []\n",
    "        for label in labels.cat.categories:\n",
    "            label_id = labels.cat.categories.get_loc(label)\n",
    "            idx = np.where(labels == label)\n",
    "            x, y = X_embedded[idx].T\n",
    "            c = cmap(label_id / num_classes)\n",
    "            scatter = ax.scatter(\n",
    "                x=x, y=y, color=c, label=label, alpha=alpha, edgecolors=\"none\"\n",
    "            )\n",
    "            handles.append(scatter)\n",
    "        ax.legend().remove()\n",
    "        set_legend(\n",
    "            handles,\n",
    "            fig,\n",
    "            ax,\n",
    "            title=y_col,\n",
    "            loc=legend_loc,\n",
    "            max_ncols=legend_max_ncols,\n",
    "            # bbox_to_anchor=(1, 1.01),\n",
    "        )\n",
    "        ax.grid(True)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072357b-5610-463a-91b3-95a89627ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res[\"embedding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde8f3c-a2b7-4569-9232-1a5be6dcea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"embedding\": res[\"embedding\"].tolist() + res[\"embedding\"].tolist(), \"label\": [f\"Label {i}\" for i in range(200)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ec14d1-32f7-4580-95d6-cbce3d524032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564d16b5-75ca-492a-82a0-5909e0eca5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_embedding(df, legend_max_ncols=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120c0e3-774f-461f-8815-eb6f32124edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_embedding(df, legend_max_ncols=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924a408-b248-437f-ae63-673bcc4ce9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BREAk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a95015-502b-40c9-b997-77f1483ead24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, get_origin, get_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e90077f-6568-4822-a81b-cb3a3c036772",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_origin(Literal[\"A\", \"B\"]) is Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c614a-9f66-4789-957c-44289ef709fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_args(Literal[\"A\", \"B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbf28e2-2bf5-413e-8024-2220ccd57653",
   "metadata": {},
   "outputs": [],
   "source": [
    "Any is Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73946a4b-6f4e-4d91-acb6-6e8db3d9c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "x = np.linspace(0, 10, 100)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.cos(x)\n",
    "y3 = np.tan(x)\n",
    "\n",
    "# Create figure and axes for the main plot\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Plot the data\n",
    "ax.plot(x, y1, label='sin(x)')\n",
    "ax.plot(x, y2, label='cos(x)')\n",
    "ax.plot(x, y3, label='tan(x)')\n",
    "\n",
    "# Create a temporary legend to get its width\n",
    "temp_legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "legend_width = temp_legend.get_window_extent(fig.canvas.get_renderer()).width\n",
    "legend_width_inches = legend_width / fig.dpi\n",
    "ax.legend_.remove()  # Remove the temporary legend\n",
    "\n",
    "# Get the current figure dimensions\n",
    "fig_width, fig_height = fig.get_size_inches()\n",
    "\n",
    "# Calculate new figure width\n",
    "new_fig_width = fig_width + legend_width_inches\n",
    "\n",
    "# Resize the figure\n",
    "fig.set_size_inches(new_fig_width, fig_height)\n",
    "\n",
    "# Adjust the main axes to make room for the legend\n",
    "main_axes_right = 1 - (legend_width_inches / new_fig_width)\n",
    "ax.set_position([ax.get_position().x0, ax.get_position().y0, main_axes_right - ax.get_position().x0, ax.get_position().height])\n",
    "\n",
    "# Add the legend\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b27894-1495-410a-9acd-d43da8a5ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "x = np.linspace(0, 10, 100)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.cos(x)\n",
    "y3 = np.tan(x)\n",
    "\n",
    "# Create figure and axes for the main plot\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Plot the data\n",
    "ax.plot(x, y1, label='sin(x)')\n",
    "ax.plot(x, y2, label='cos(x)')\n",
    "ax.plot(x, y3, label='tan(x)')\n",
    "\n",
    "# # Create a temporary legend to get its width\n",
    "# temp_legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "# legend_width = temp_legend.get_window_extent(fig.canvas.get_renderer()).width\n",
    "# legend_width_inches = legend_width / fig.dpi\n",
    "# ax.legend_.remove()  # Remove the temporary legend\n",
    "\n",
    "# # Get the current figure dimensions\n",
    "# fig_width, fig_height = fig.get_size_inches()\n",
    "\n",
    "# # Calculate new figure width\n",
    "# new_fig_width = fig_width + legend_width_inches\n",
    "\n",
    "# # Resize the figure\n",
    "# fig.set_size_inches(new_fig_width, fig_height)\n",
    "\n",
    "# # Adjust the main axes to make room for the legend\n",
    "# main_axes_right = 1 - (legend_width_inches / new_fig_width)\n",
    "# ax.set_position([ax.get_position().x0, ax.get_position().y0, main_axes_right - ax.get_position().x0, ax.get_position().height])\n",
    "\n",
    "# Add the legend\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f7b805-05d5-4064-b4b6-f925ff20a921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e0d41-0c06-473d-84e5-32b57f7e7ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d263a58-af9f-4f65-bbd3-94bd9431bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"classifier.\"):\n",
    "        # ignore classifier layer since it dynamically changes\n",
    "        continue\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0727e718-5939-41aa-94b4-39d478e62832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
